{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "import itertools\n",
    "scripts_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'scripts'))\n",
    "sys.path.insert(0, scripts_dir)\n",
    "import data_processing as data_pr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define paths and names\n",
    "data_paths = data_pr.get_datapaths('HousePrices')\n",
    "data_in, data_info = data_pr.get_data(data_paths, print_output=True, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = re.findall('^\\w+:.+?\\n\\s*\\n', data_info, flags=re.MULTILINE)\n",
    "categs = [heading.split(':')[0] for heading in x]\n",
    "descripts = re.split('^\\w+:.+?\\n\\s*\\n', data_info, flags=re.MULTILINE)[1:]\n",
    "options = [re.findall('^\\s+([\\w|\\.|\\&| |\\(\\|\\)]+)\\t', des, flags=re.MULTILINE) for des in descripts]\n",
    "print('number of descriptions: ', len(descripts))\n",
    "print('numbers of categories: ', len(categs))\n",
    "options_dict = {cat:opt for cat, opt in zip(categs, options)}\n",
    "for k, v in options_dict.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different methods of transforming data\n",
    "scalar_inputs = ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\\\n",
    "                 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'TotRmsAbvGrd', 'GarageYrBlt', 'GarageCars', 'GarageArea',\\\n",
    "                 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'YrSold', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\\\n",
    "                    'KitchenAbvGr', 'Fireplaces']\n",
    "to_scalar = ['LotShape', 'LandSlope', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'CentralAir', 'Functional',\\\n",
    "             'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'KitchenQual', 'FireplaceQu', 'HeatingQC']\n",
    "one_hot = ['MSSubClass', 'MSZoning', 'Street', 'LotConfig', 'Neighborhood', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'Foundation',\\\n",
    "            'SaleType', 'SaleCondition']\n",
    "one_hot_plus = {'Alley': {'NA': 0}, 'LandContour': {'Lvl': 0}, 'MasVnrType': {'None': 0, 'NA': 'dist', 'weight': 'MasVnrArea'}, 'GarageType':{'NA': 0},\\\n",
    "                 'MiscFeature': {'NA': 0, 'weight': 'MiscVal'}, 'Heating': {'weight': 'HeatingQC'}}\n",
    "case_by_case = ['Utilities', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'BsmtFinType1', 'BsmtFinType2',\\\n",
    "               'Electrical']\n",
    "#post processing\n",
    "#delete TotalBsmtSF\n",
    "#do to_scalar transformation and replace cols in data_in\n",
    "#transform MoSold and add to year\n",
    "#transform one hot, one hot plus and case to case entries. Store in a dictionary.\n",
    "#Change NA in Electrical to dist of the other entries. Remove NA\n",
    "#combine the transformed entries in the dict back into the original dataframe. Check for repeats\n",
    "#take mean and var of each feature and scale and renormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get types in options_dict to match the types in data_in\n",
    "for k in data_in.keys():\n",
    "    if k in options_dict:\n",
    "        if k in one_hot+list(one_hot_plus.keys()):\n",
    "            if type(data_in[k][0])!=str:\n",
    "                data_in[k] = data_in[k].apply(str)\n",
    "        #gather the unique elements in data_in[k], the set of all values of the variable with heading k\n",
    "        actual_opts = list(set(data_in[k].tolist()))\n",
    "        actual_type = type(actual_opts[0])\n",
    "        #if the type of the variable is something other than str, need to convert options_dict variable options to the correct type\n",
    "        if options_dict[k] == []:  #this represents a free numeric entry\n",
    "            options_dict[k] = {'variable_type': actual_type}  #what type is this entry in data_in to start?\n",
    "            #keep working here\n",
    "        else:\n",
    "            #if the type of a column in data_in is something other than a string, \n",
    "            #the options of the corresponding key in options_dict will have to be converted \n",
    "            if actual_type != str: \n",
    "                options_dict[k] = [actual_type(item) for item in options_dict[k]]\n",
    "\n",
    "            #check if there exist any items in data_in that do not appear in opitons_dict and raise an error if so\n",
    "            check_options = [item in options_dict[k] for item in actual_opts]\n",
    "            if not all(check_options):\n",
    "                print(check_options)\n",
    "                false_idx = -1\n",
    "                num_false = check_options.count(False)\n",
    "                for n in range(num_false):\n",
    "                    false_idx = check_options.index(False, false_idx+1)\n",
    "                    print(f'ERROR: value {actual_opts[false_idx]} for key {k} does not exist in options_dict')           \n",
    "    #if this key does not exist in options_dict and it is not a special key, then raise an error\n",
    "    elif k !='SalePrice' and k!= 'Id':\n",
    "        print(f'ERROR: key {k} in the data is not in options_dict')\n",
    "\n",
    "for k, v in options_dict.items():\n",
    "    print(f\"{k}: {v}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_type = float\n",
    "for k, v in data_in.items():\n",
    "    all_numeric=False\n",
    "    free_var=False\n",
    "    if k in options_dict:\n",
    "        #print(k)\n",
    "        #check if all options are numeric \n",
    "        if type(options_dict[k])==list: #if options are explicitly listed and they are strings then check if they are strings of numeric values\n",
    "            if type(options_dict[k][0])==str:\n",
    "                numeric = [item.replace('.', '').replace('-', '').replace(' ', '').isnumeric() for item in options_dict[k]] #remove special characters\n",
    "                all_numeric = all(numeric)\n",
    "        elif type(options_dict[k])==dict: #if options are described by a dictionary then the the data type is a free form number\n",
    "            if options_dict[k]['variable_type']==str: #if that number is currently in the form of a string then it must be converted\n",
    "                all_numeric=True\n",
    "                free_var=True\n",
    "        if all_numeric and k != 'MSSubClass':\n",
    "            #print(options_dict[k])\n",
    "\n",
    "            #before converting, replace 'NA' with -1\n",
    "            data_in[k] = data_in[k].replace('NA', -1)\n",
    "            data_in[k] = data_in[k].astype(float_type) #convert data\n",
    "            #print('type: ', type(data_in[k].loc[1]))\n",
    "\n",
    "            #convert options dict as well\n",
    "            if free_var:\n",
    "                options_dict[k]['variable_type']=float_type\n",
    "            else:\n",
    "                options_dict[k] = [float_type(item) for item in options_dict[k]]\n",
    "\n",
    "for k, v in options_dict.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count keys to make sure they add up to the right number\n",
    "full_list = one_hot + scalar_inputs +  to_scalar + case_by_case + list(one_hot_plus.keys()) + ['MasVnrArea', 'MiscVal']\n",
    "for item in full_list:\n",
    "    if item not in categs:\n",
    "        print(item)\n",
    "his = Counter(full_list)\n",
    "for k,v in his.items():\n",
    "    if v>1:\n",
    "        print(f'key {k} has more than one occurance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_series(old_series, pos, new_label, val):\n",
    "    new_index  = old_series.index.insert(pos, new_label)\n",
    "    # insert into the underlying array of values\n",
    "    new_values = np.insert(old_series.values, pos, val)\n",
    "    new_series = pd.Series(new_values, index=new_index)\n",
    "    return new_series\n",
    "\n",
    "def input_dist(df_new, key, dist=None):\n",
    "    if dist is None:\n",
    "        dist = df_new[df_new[key]!=1.].mean() #find distribution of different values excluding unknowns\n",
    "    else:\n",
    "        dist = add_to_series(dist, df_new.columns.get_loc(key), key, 0) #add an entry to dist for key\n",
    "    df_new[df_new[key]==1] = dist #Give the unknowns the distribution of inputs\n",
    "    #drop unknown column from df_new and dist\n",
    "    df_new = df_new.drop(columns=[key])\n",
    "    dist = dist.drop(index=key)\n",
    "    return df_new, dist\n",
    "\n",
    "def to_one_hot(data_in, categ, dtype=float):\n",
    "    num_data = len(data_in)\n",
    "    one_col = data_in[categ] #extract the column we want to transform\n",
    "    actual_opts = list(set(one_col.tolist())) #extract possible values entries in that column have\n",
    "    #print(actual_opts)\n",
    "    to_add = []\n",
    "    for item in options_dict[categ]:\n",
    "        #add missing entries\n",
    "        if item not in actual_opts:\n",
    "            one_col.loc[len(one_col)] = item  # adding a row\n",
    "    df1 = pd.get_dummies(one_col, dtype=dtype) #transform to one hot encoding\n",
    "    df1 = df1.loc[:num_data-1] #remove extra rows\n",
    "    return df1\n",
    "\n",
    "def to_one_hot_plus(data_in, categ, conv_dict, dist=None):\n",
    "    df_new = to_one_hot(data_in, categ) #transform to one hot encoding\n",
    "    #consider special cases\n",
    "    for k2, val in conv_dict.items():\n",
    "        if val==0:\n",
    "            df_new = df_new.drop(columns=[k2])\n",
    "        elif val=='dist':\n",
    "            df_new, dist = input_dist(df_new, k2, dist=dist)\n",
    "        elif k2=='weight':\n",
    "            df_new = df_new.mul(data_in[val], axis=0)\n",
    "    if dist is not None:\n",
    "        dist = dist[dist.index.isin(df_new.columns)]\n",
    "\n",
    "    return df_new, dist\n",
    "\n",
    "def create_mappings(to_scalar, options_dict):\n",
    "    mappings = {}\n",
    "    for k in to_scalar:\n",
    "        num_opts = len(options_dict[k])\n",
    "        \n",
    "        # define mapping in descending order from 1 to 0.\n",
    "        mappings[k] = {opt: 1-i/(num_opts-1) for i, opt in enumerate(options_dict[k])}\n",
    "    return mappings\n",
    "\n",
    "def cat_to_vec(init_df, mapping, new_cols=None, cat=None):\n",
    "    if cat is None:\n",
    "        cat = init_df.columns[0]\n",
    "    vec = init_df[cat].map(mapping)\n",
    "\n",
    "    # turn listâ€values into real columns\n",
    "    vec_df = pd.DataFrame(vec.tolist(),\n",
    "                    index=init_df.index,\n",
    "                    columns=new_cols)\n",
    "    return vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform columns in the to_scalar category\n",
    "mappings = create_mappings(to_scalar, options_dict)\n",
    "for k in to_scalar:\n",
    "    data_in[k] = data_in[k].map(mappings[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = data_in.drop(columns='TotalBsmtSF')\n",
    "data_in['YrSold'] = data_in['YrSold'] + data_in['MoSold']/12 - 1/24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = data_in.drop(columns='MoSold')\n",
    "data_in.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in one_hot + list(one_hot_plus.keys()):\n",
    "    if type(data_in[key][0])!=str:\n",
    "        print(key)\n",
    "        data_in[key] = data_in[key].apply(str)\n",
    "        print(type(data_in[key][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform those in the one_hot_plus category\n",
    "dfs={}\n",
    "dists = {}\n",
    "for k, val in one_hot_plus.items():\n",
    "    df_new, dist = to_one_hot_plus(data_in, k, val)\n",
    "    if dist is not None:\n",
    "        dists[k] = dist\n",
    "    dfs[k] = df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform those in the one_hot category\n",
    "for categ in one_hot:\n",
    "    df1 = to_one_hot(data_in, categ)\n",
    "    dfs[categ] = df1\n",
    "    #df = pd.concat([df, df1.drop(list(np.arange(len(data_in), len(df1))))], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define mappings for case by case features\n",
    "mappings = {'Utilities': [{'AllPub':[1, 1, 1], 'NoSewr':[0, 1, 1], 'NoSeWa':[0, 0, 1], 'ELO':[0, 0, 0]}, ['Sew', 'Wat', 'Gas']],\n",
    "           'Condition1': [{'Artery':[1, 0, 0, 0], 'Feedr':[0.5, 0, 0, 0], 'Norm': [0, 0, 0, 0], 'RRNn': [0, 0.5, 0, 0],\n",
    "                           'RRAn':[0, 1, 0, 0], 'PosN':[0, 0, 0, .5], 'PosA': [0, 0, 0, 1], 'RRNe':[0, 0, 0.5, 0], 'RRAe': [0, 0, 1, 0]},\n",
    "                           ['Road', 'NS_rail', 'EW_rail', 'Positive']],#add to Condition2\n",
    "            'Condition2': 'Condition1',\n",
    "            'BldgType': [{'1Fam':[0, 0], '2fmCon':[1, 0], 'Duplex': [0.5, 0], 'TwnhsE':[0, 0.5], 'TwnhsI': [0, 1], 'Twnhs':[0, 1]},\n",
    "                           ['2fam', 'Twnhs']],\n",
    "            'HouseStyle': [{'1Story': [0, 0, 0], '1.5Fin': [0.4, 0, 0], '1.5Unf': [0.2, 0, 0], '2Story': [0.6, 0, 0], '2.5Fin':[1, 0, 0],\n",
    "                            '2.5Unf':[0.8, 0, 0], 'SFoyer': [0, 1, 0], 'SLvl': [0, 0, 1]}, ['Stories', 'SFoyer', 'SLvl']],\n",
    "            'BsmtFinType1': [{'NA': [0], 'Unf': [0], 'LwQ':[0.2], 'Rec':[0.4], 'BLQ':[0.6], 'ALQ':[0.8], 'GLQ':[1]},\n",
    "                             ['BsmtFiQual1']],\n",
    "       \t    'BsmtFinType2': [{'NA': [0], 'Unf': [0], 'LwQ':[0.2], 'Rec':[0.4], 'BLQ':[0.6], 'ALQ':[0.8], 'GLQ':[1]},\n",
    "                             ['BsmtFiQual2']],\n",
    "            'Electrical': [{'SBrkr':[1, 0, 0], 'FuseA':[2/3, 0, 0], 'FuseF':[1/3, 0, 0], 'FuseP':[0, 0, 0], 'Mix':[0, 1, 0], 'NA':[0, 0, 1]},\n",
    "                           ['BreakWire_rate', 'Mixed', 'NA']]\n",
    "                           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 'Utilities'\n",
    "print(data_in[k])\n",
    "new_df = cat_to_vec(data_in, mappings[k][0], new_cols=mappings[k][1], cat=k)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in mappings.items():\n",
    "    if type(v)==str:\n",
    "        v = mappings[mappings[k]]\n",
    "    dfs[k] = cat_to_vec(data_in, v[0], new_cols=v[1], cat=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(data_in['Electrical']=='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new, dist = input_dist(dfs['Electrical'], 'NA', dist=None)\n",
    "dists['Electrical'] = dist\n",
    "dfs['Electrical'] = df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = data_in.drop(columns=list(dfs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dict = {k: list(v.columns) for k, v in dfs.items()}\n",
    "all_keys = list(itertools.chain(*[v for v in cols_dict.values()]))\n",
    "freq = Counter(all_keys)\n",
    "repeat_cols=[]\n",
    "for k, v in freq.items():\n",
    "    if v>=2:\n",
    "        print('column ', k, ' has repeats')\n",
    "        repeat_cols.append(k)\n",
    "repeat_keys = []\n",
    "s_rcol = set(repeat_cols)\n",
    "for k, v in cols_dict.items():\n",
    "    if any(item in s_rcol for item in v):\n",
    "        repeat_keys.append(k)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(repeat_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in dfs.keys():\n",
    "    #print(f\"type of {k}: \", type(k))\n",
    "    #print(f\"type of cols of {k}\", type(dfs[k].columns[0]))\n",
    "    if k in repeat_keys:\n",
    "        pref = k\n",
    "    else:\n",
    "        pref = k[:3]\n",
    "    rename_dict = {name: pref + '_' + name for name in cols_dict[k]}\n",
    "    dfs[k] = dfs[k].rename(columns=rename_dict)\n",
    "\n",
    "print(dfs['Electrical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in dfs.values():\n",
    "    data_in = pd.concat([data_in, v], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(data_in.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of one_hot encoding columns\n",
    "total = 0\n",
    "for item in one_hot:\n",
    "    total += len(options_dict[item])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(data_in[data_in['BsmtFinType1']=='NA']['BsmtFinSF1'])\n",
    "np.sum(data_in['TotalBsmtSF'] == data_in['BsmtUnfSF'] + data_in['BsmtFinSF1'] + data_in['BsmtFinSF2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data_in['MoSold'].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HousePrices",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
